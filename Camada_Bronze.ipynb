{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26913acc",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters (papermill picks this up)\n",
    "PROJECT_ID = \"nice-proposal-467718-q6\"\n",
    "REGION = \"us-west1\"\n",
    "BRONZE_PATH = \"gs://meu-bucket-premier/bronze/\"\n",
    "RUN_TS = None  # auto-set if None\n",
    "\n",
    "# Kaggle dataset in the form \"owner/dataset\"\n",
    "KAGGLE_DATASET = \"hugomathien/soccer\"   # <- ajuste para o seu dataset\n",
    "# Optionally filter which files to upload (None = all)\n",
    "KAGGLE_FILES_FILTER = None              # e.g., [\"*.csv\"] ou [\"database.sqlite\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3f2173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_TS = 20250815-153852\n",
      "kaggle.json OK\n"
     ]
    }
   ],
   "source": [
    "# bootstrap: deps + checagens\n",
    "import sys, os, shutil, fnmatch, subprocess\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "\n",
    "# Instalar pacotes que podem faltar\n",
    "def ensure(pkg, pip_name=None):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ModuleNotFoundError:\n",
    "        pip = pip_name or pkg\n",
    "        print(f\"Instalando {pip} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", pip])\n",
    "\n",
    "ensure(\"kaggle\")\n",
    "ensure(\"google.cloud.storage\", \"google-cloud-storage\")\n",
    "\n",
    "# Timestamp lógico\n",
    "if RUN_TS is None:\n",
    "    RUN_TS = dt.datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(\"RUN_TS =\", RUN_TS)\n",
    "\n",
    "# Kaggle token\n",
    "home = Path.home()\n",
    "kaggle_json = home / \".kaggle\" / \"kaggle.json\"\n",
    "if not kaggle_json.exists():\n",
    "    raise RuntimeError(\"kaggle.json não encontrado em ~/.kaggle/kaggle.json — suba o arquivo e rode: chmod 600 ~/.kaggle/kaggle.json\")\n",
    "os.chmod(kaggle_json, 0o600)\n",
    "print(\"kaggle.json OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1883d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando dataset: hugomathien/soccer\n",
      "Dataset URL: https://www.kaggle.com/datasets/hugomathien/soccer\n",
      "License(s): ODbL-1.0\n",
      "1 arquivos baixados do Kaggle.\n"
     ]
    }
   ],
   "source": [
    "# baixa dataset do Kaggle e descompacta em /tmp/kaggle_dl\n",
    "workdir = Path(\"/tmp/kaggle_dl\")\n",
    "if workdir.exists():\n",
    "    shutil.rmtree(workdir)\n",
    "workdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Baixando dataset:\", KAGGLE_DATASET)\n",
    "subprocess.check_call([\"kaggle\", \"datasets\", \"download\", \"-d\", KAGGLE_DATASET, \"-p\", str(workdir), \"-q\"])\n",
    "\n",
    "# Descompacta\n",
    "for z in workdir.glob(\"*.zip\"):\n",
    "    shutil.unpack_archive(str(z), extract_dir=str(workdir))\n",
    "    z.unlink()\n",
    "\n",
    "files = [p for p in workdir.rglob(\"*\") if p.is_file()]\n",
    "print(f\"{len(files)} arquivos baixados do Kaggle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68cfe04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtro opcional de arquivos\n",
    "if KAGGLE_FILES_FILTER:\n",
    "    filtered = []\n",
    "    for pattern in KAGGLE_FILES_FILTER:\n",
    "        filtered += [p for p in files if fnmatch.fnmatch(p.name, pattern)]\n",
    "    # remove duplicados mantendo ordem\n",
    "    seen = set()\n",
    "    files = [x for x in filtered if not (x in seen or seen.add(x))]\n",
    "    print(f\"Após filtro {KAGGLE_FILES_FILTER}: {len(files)} arquivos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed6f85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload concluído: 1 arquivos para gs://meu-bucket-premier/bronze/20250815-153852/hugomathien_soccer/\n"
     ]
    }
   ],
   "source": [
    "# upload para GCS (Bronze)\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket_name = BRONZE_PATH.replace(\"gs://\",\"\").split(\"/\")[0]\n",
    "prefix = \"/\".join(BRONZE_PATH.replace(\"gs://\",\"\").split(\"/\")[1:]).rstrip(\"/\")\n",
    "\n",
    "dataset_tag = KAGGLE_DATASET.replace(\"/\", \"_\")\n",
    "gcs_prefix = f\"{prefix}/{RUN_TS}/{dataset_tag}\" if prefix else f\"{RUN_TS}/{dataset_tag}\"\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "uploaded = 0\n",
    "for p in files:\n",
    "    rel = p.relative_to(Path(\"/tmp/kaggle_dl\")).as_posix()\n",
    "    blob_path = f\"{gcs_prefix}/{rel}\"\n",
    "    bucket.blob(blob_path).upload_from_filename(str(p))\n",
    "    uploaded += 1\n",
    "    if uploaded % 10 == 0:\n",
    "        print(f\"↑ {uploaded} arquivos...\")\n",
    "\n",
    "print(f\"Upload concluído: {uploaded} arquivos para gs://{bucket_name}/{gcs_prefix}/\")\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
